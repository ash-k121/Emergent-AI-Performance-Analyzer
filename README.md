# ğŸ“Š Emergent AI Effectiveness Analysis

This project evaluates the **performance and trustworthiness of an Emergent AI system** deployed between **November 2023 and October 2024**, using a combination of **self-generated user-level and weekly aggregate datasets**. The analysis was visualized using **Tableau dashboards**, focusing on behavioral and performance indicators.

---

## ğŸ” Objective

To analyze how well the AI performs independently, completes assigned tasks, and retains user trust after failure. This evaluation helps assess the AIâ€™s real-world readiness in B2C-like environments.

---

## ğŸ§  Key Metrics

- **Autonomy Index**: Measures how independently the AI completes tasks without human intervention.
- **Task Completion Rate**: Percentage of tasks completed out of those assigned â€” reflects task success efficiency.
- **Trust Retention Rate**: Percentage of users who continue using the AI system after experiencing an error or failure.
- **Conversion Rate & Feature Adoption**: Indicates how effectively users convert to paying customers and adopt AI-powered features.

---

## ğŸ“ Datasets

### 1. Weekly Aggregated Data
- `Week`
- `Signups`
- `Active Users`
- `Paid Users`
- `Feature Uses`
- `Conversion Rate (%)`
- `Feature Adoption Rate (%)`

### 2. User-Level Metrics
- `User_ID`
- `Tasks_Assigned`
- `Tasks_Completed`
- `Interventions` (manual overrides)
- `Agent_Errors`
- `Retained_After_Error` (1/0)
- `Active_Agents`
- `Avg_Task_Exec_Time`
- `Autonomy_Index`
- `Trust_Retention_Rate`
- `Task_Completion_Rate`

> ğŸ’¡ Both datasets were synthetically generated to simulate real-world AI usage behavior.

---

## ğŸ› ï¸ Tools & Technologies

- **Tableau** â€“ For dashboarding and visual analytics
- **Python & Excel** â€“ For dataset generation and pre-processing
- **Custom Metric Design** â€“ To assess AI autonomy, reliability, and user trust

---

## ğŸ“Š Dashboard Highlights

- Interactive visualizations showing weekly trends in signups, active users, and feature usage
- Time-series analysis of task completions and manual interventions
- User retention metrics post-AI failure
- Drill-down analysis by individual users and agents

---

## ğŸ’¡ Why This Project Matters

With AI systems handling more autonomous functions, understanding how they perform â€” and how users respond to errors â€” is essential. This project demonstrates how **behavioral metrics and visual storytelling** can uncover important insights about:

- AIâ€™s ability to operate independently
- System reliability under real-world conditions
- How failures affect user trust and retention

---

