# 📊 Emergent AI Effectiveness Analysis

This project evaluates the **performance and trustworthiness of an Emergent AI system** deployed between **November 2023 and October 2024**, using a combination of **self-generated user-level and weekly aggregate datasets**. The analysis was visualized using **Tableau dashboards**, focusing on behavioral and performance indicators.

---

## 🔍 Objective

To analyze how well the AI performs independently, completes assigned tasks, and retains user trust after failure. This evaluation helps assess the AI’s real-world readiness in B2C-like environments.

---

## 🧠 Key Metrics

- **Autonomy Index**: Measures how independently the AI completes tasks without human intervention.
- **Task Completion Rate**: Percentage of tasks completed out of those assigned — reflects task success efficiency.
- **Trust Retention Rate**: Percentage of users who continue using the AI system after experiencing an error or failure.
- **Conversion Rate & Feature Adoption**: Indicates how effectively users convert to paying customers and adopt AI-powered features.

---

## 📁 Datasets

### 1. Weekly Aggregated Data
- `Week`
- `Signups`
- `Active Users`
- `Paid Users`
- `Feature Uses`
- `Conversion Rate (%)`
- `Feature Adoption Rate (%)`

### 2. User-Level Metrics
- `User_ID`
- `Tasks_Assigned`
- `Tasks_Completed`
- `Interventions` (manual overrides)
- `Agent_Errors`
- `Retained_After_Error` (1/0)
- `Active_Agents`
- `Avg_Task_Exec_Time`
- `Autonomy_Index`
- `Trust_Retention_Rate`
- `Task_Completion_Rate`

> 💡 Both datasets were synthetically generated to simulate real-world AI usage behavior.

---

## 🛠️ Tools & Technologies

- **Tableau** – For dashboarding and visual analytics
- **Python & Excel** – For dataset generation and pre-processing
- **Custom Metric Design** – To assess AI autonomy, reliability, and user trust

---

## 📊 Dashboard Highlights

- Interactive visualizations showing weekly trends in signups, active users, and feature usage
- Time-series analysis of task completions and manual interventions
- User retention metrics post-AI failure
- Drill-down analysis by individual users and agents

---

## 💡 Why This Project Matters

With AI systems handling more autonomous functions, understanding how they perform — and how users respond to errors — is essential. This project demonstrates how **behavioral metrics and visual storytelling** can uncover important insights about:

- AI’s ability to operate independently
- System reliability under real-world conditions
- How failures affect user trust and retention

---

